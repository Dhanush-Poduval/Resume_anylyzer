{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRTkNCT1B3h5mSwWB8rwj2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush-Poduval/Resume_anylyzer/blob/main/resume_anilyser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kzLYEV0CHN-1",
        "outputId": "48f54e1a-d105-4a18-ee4c-1959f1577415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from wordcloud) (3.10.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2 python-docx spacy wordcloud\n",
        "!pip install nltk\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "reader = PdfReader(\"Resume_Latest.pdf\")\n",
        "text = \"\"\n",
        "for i, page in enumerate(reader.pages):\n",
        "    page_text = page.extract_text()\n",
        "    text += page_text + \"\\n\"\n",
        "    print(text)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "\n",
        "clean_tokens = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "\n",
        "programming_languages = [\n",
        "\n",
        "    'Python', 'Java', 'JavaScript', 'C', 'C++', 'C#', 'Ruby', 'PHP',\n",
        "    'Swift', 'Kotlin', 'Go', 'TypeScript', 'Dart', 'Rust', 'Scala', 'Objective-C',\n",
        "    'HTML', 'CSS', 'XML', 'SQL', 'JSON', 'JSX', 'SASS', 'SCSS', 'Less',\n",
        "    'R', 'MATLAB', 'Julia', 'SAS', 'Bash', 'Shell', 'Perl', 'Lisp', 'Haskell',\n",
        "    'F#', 'Erlang', 'Ada', 'Fortran', 'COBOL', 'Prolog', 'Scheme',\n",
        "    'VBA', 'Assembly', 'Solidity', 'Apex', 'Elixir', 'Groovy', 'Crystal', 'Elm'\n",
        "]\n",
        "found_languages = [token for token in clean_tokens if token in programming_languages]\n",
        "\n",
        "percentages = re.findall(r'\\b\\d{1,3}(?:\\.\\d+)?\\s?%', text)\n",
        "cgpas = re.findall(r'\\b\\d\\.\\d{1,2}/10\\b', text)\n",
        "\n",
        "entities = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in ['PERSON','ORG','DATE','GPE']]\n",
        "\n",
        "\n",
        "\n",
        "tech_terms = ['Python','JavaScript','HTML','CSS','ReactJS','NodeJS','Flask','TensorFlow',\n",
        "              'Data Structures','Design and Analysis of Algorithms']\n",
        "\n",
        "skills=[token for token in clean_tokens if token in programming_languages]\n",
        "\n",
        "companies = []\n",
        "for ent_text, ent_label in entities:\n",
        "    if ent_label == 'ORG':\n",
        "        if not any(term in ent_text for term in tech_terms):\n",
        "            companies.append(ent_text)\n",
        "\n",
        "\n",
        "\n",
        "resume_data = {\n",
        "    'Name': [ent[0] for ent in entities if ent[1]=='PERSON'],\n",
        "    'Companies': companies,\n",
        "    'Dates': [ent[0] for ent in entities if ent[1]=='DATE'],\n",
        "    'Languages': found_languages,\n",
        "    'Percentages': percentages,\n",
        "    'CGPAs': cgpas\n",
        "}\n",
        "print(resume_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GHHg69-0JXra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b90762b-4cd3-44a4-f46b-3e7caec2e875"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dhruv Poduval\n",
            "/githubhttps://github.com/dhruvpoduval |/linkedinlinkedin.com/in/dhruv-poduval-02aab2261 |/envel⌢pe\n",
            "dhruvpoduval@gmail.com\n",
            "Education\n",
            "PES University 2021-2025\n",
            "B.Tech Computer Science Current GPA: 8.52/10\n",
            "National Public School 2019-2021\n",
            "12th% - 96.8%\n",
            "Coursework\n",
            "Courses: Data Structures and Applications, Design and Analysis of Algorithms, Machine Intelligence,\n",
            "Database Management Systems, Data Analytics, Database Technologies, Object Oriented Design and\n",
            "Analysis, Generic Programming in C++.\n",
            "Awards: 2x recipient of the MRD Scholarship for placing in the top 20% at the end of the semester.\n",
            "Skills\n",
            "Languages : C/C++(intermediate), Python, JavaScript(basic), HTML/CSS(basic), Java(basic), MySQL, MongoDB\n",
            "Tools : Git/GitHub, VS Code, Docker\n",
            "Libraries and Frameworks : ReactJS, NodeJS, Express, Flask, REST API’s\n",
            "Experience\n",
            "VuNet Systems |Software Engineering Intern Jan – Aug 2025\n",
            "•Engineered modular UI automation test suites using Selenium andPlaywright , validating critical workflows in a\n",
            "distributed cloud-native observability platform deployed on Kubernetes .\n",
            "•Automated observability data pipeline setup, including enabling telemetry sources, installing agents, and validating\n",
            "end-to-end data flow via Kafka topics.\n",
            "•Contributed to infrastructure validation by simulating user-driven installation and deployment flows on VMs,\n",
            "enhancing release stability across environments.\n",
            "•Collaborated with backend and DevOps teams to debug pod failures, analyze Helm-based service orchestration, and\n",
            "ensure alignment of UI behavior with backend service states.\n",
            "•Tested and enhanced an AI-powered in-product assistant by validating NLP query handling, response correctness,\n",
            "and underlying intent-resolution mechanisms.\n",
            "•Integrated test flows into CI/CD pipelines (Jenkins), ensuring automation coverage for new features and\n",
            "improving feedback cycles during product releases.\n",
            "Projects\n",
            "File Metadata Analyzer |C++, Templates, Generic Programming\n",
            "•Built a File Metadata Analyzer using templates and generic programming in C++.\n",
            "•Applied the concept of templates, including variadic templates and template specialization, to read information\n",
            "about different kinds of files and display the corresponding metadata.\n",
            "•Also applied concepts and constraints in the project to restrict template behavior based in file type.\n",
            "Stock Portfolio Management System |Python, Flask, API(Finnhub), MySQL, Database Management\n",
            "•Developed a basic stock portfolio management system using python Flask, and stock API’s to get real time data\n",
            "about prices of stock.\n",
            "•The system allowed users to buy and sell stocks based on the prices of the stock at that particular time, and see\n",
            "how profitable the transaction was. All information was stored in a database.\n",
            "•The API was used to get real time stock prices. Using these prices, graphical representations were provided for the\n",
            "stock on a yearly, monthly, or daily basis.\n",
            "Sentiment Analysis using Deep Learning |TensorFlow, python, cv2, VS Code\n",
            "•Engineered a system that could detect emotion from an image of the face.\n",
            "•Used convolution neural networks with TensorFlow to train a model on a set of over 800 images, which then\n",
            "detected 7 different classes of emotion.\n",
            "•Added a functionality where the system could access a webcam and detect emotion in real time.\n",
            "\n",
            "{'Name': ['Dhruv Poduval', 'Kafka', 'Jenkins', 'Templates'], 'Companies': ['PES University', 'B.Tech Computer Science Current GPA', 'National Public School', 'Database Management Systems', 'Data Analytics', 'Generic Programming', 'the MRD Scholarship', 'Docker\\nLibraries', 'API', 'VuNet Systems', 'UI', 'Kubernetes', 'observability data pipeline setup', 'DevOps', 'UI', 'NLP', 'CI', 'Generic Programming', 'MySQL, Database Management', 'API', 'API'], 'Dates': ['2021-2025', 'the end of the semester', '2025', 'monthly', 'daily'], 'Languages': ['C++', 'C', 'Python', 'HTML', 'C++'], 'Percentages': ['96.8%', '20%'], 'CGPAs': ['8.52/10']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shamimhasan8/resume-vs-job-description-matching-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "\n",
        "path = \"/kaggle/input/resume-vs-job-description-matching-dataset\"\n",
        "print(os.listdir(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfZS6HWExwwo",
        "outputId": "04948a7e-7813-472b-d468-555081129f3c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shamimhasan8/resume-vs-job-description-matching-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 927k/927k [00:00<00:00, 69.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/shamimhasan8/resume-vs-job-description-matching-dataset/versions/1\n",
            "['resume_job_matching_dataset.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "path = \"/root/.cache/kagglehub/datasets/shamimhasan8/resume-vs-job-description-matching-dataset/versions/1\"\n",
        "file_path = os.path.join(path, \"resume_job_matching_dataset.csv\")\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34AN7V5BzDES",
        "outputId": "b1ded6c8-b335-4174-af39-d405cfd5cb31"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     job_description  \\\n",
            "0  Data Analyst needed with experience in SQL, Ex...   \n",
            "1  Data Scientist needed with experience in Stati...   \n",
            "2  Software Engineer needed with experience in Sy...   \n",
            "3  ML Engineer needed with experience in Python, ...   \n",
            "4  Software Engineer needed with experience in RE...   \n",
            "\n",
            "                                              resume  match_score  \n",
            "0  Experienced professional skilled in SQL, Power...            4  \n",
            "1  Experienced professional skilled in Python, De...            4  \n",
            "2  Experienced professional skilled in wait, Git,...            5  \n",
            "3  Experienced professional skilled in return, De...            4  \n",
            "4  Experienced professional skilled in REST APIs,...            5  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 3 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   job_description  10000 non-null  object\n",
            " 1   resume           10000 non-null  object\n",
            " 2   match_score      10000 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 234.5+ KB\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}